<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-Time Face Detection</title>
    <link rel="stylesheet" type="text/css" href="css/face capture.css">
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
    <style>
        #video {
            display: block;
            margin: 0 auto;
        }
        #canvas {
            display: block;
            margin: 0 auto;
        }
    </style>
</head>
<body class="container">
    <h1>Real-Time Face Detection</h1>
    <video id="video" width="640" height="480" autoplay muted></video>
    <canvas id="canvas" width="640" height="480"></canvas>
    
    <script type="text/javascript">
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');

        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { width: 640, height: 480 },
                audio: false,
            });
            video.srcObject = stream;
            return new Promise((resolve) => {
                video.onloadedmetadata = () => {
                    resolve(video);
                };
            });
        }

        async function detectFaces() {
            const model = await blazeface.load();
            const returnTensors = false; // Pass in `true` to get tensors back, instead of values.
            const flipHorizontal = false; // Flip for webcam
            const annotateBoxes = true;
            const predictions = await model.estimateFaces(video, returnTensors, flipHorizontal, annotateBoxes);

            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            if (predictions.length > 0) {
                predictions.forEach((prediction) => {
                    const start = prediction.topLeft;
                    const end = prediction.bottomRight;
                    const size = [end[0] - start[0], end[1] - start[1]];

                    ctx.beginPath();
                    ctx.rect(start[0], start[1], size[0], size[1]);
                    ctx.lineWidth = 2;
                    ctx.strokeStyle = 'red';
                    ctx.stroke();
                });
            }

            requestAnimationFrame(detectFaces);
        }

        async function main() {
            await setupCamera();
            video.play();
            detectFaces();
        }

        main();
    </script>
</body>
</html>
